{
    "sourceFile": "retrievers/faiss_retriever.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 13,
            "patches": [
                {
                    "date": 1732257699981,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1732259580044,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,9 +39,9 @@\n     base = \".\"\n     model_name = \"bge\"\n     model_dict = {\n         \"m3e\": base + \"/pre_train_model/m3e-large\",\n-        \"bge\": \"bge-large-zh\"\n+        \"bge\": \"BAAI/bge-large-zh\"\n     }\n     model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n"
                },
                {
                    "date": 1732259911496,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,9 +39,9 @@\n     base = \".\"\n     model_name = \"bge\"\n     model_dict = {\n         \"m3e\": base + \"/pre_train_model/m3e-large\",\n-        \"bge\": \"BAAI/bge-large-zh\"\n+        \"bge\": base + \"/pre_train_model/bge-large-zh-embed\"\n     }\n     model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n"
                },
                {
                    "date": 1732260377807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,14 +46,14 @@\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n     dp.ParseBlock(max_seq = 512)\n     print(len(dp.data))\n-    dp.ParseAllPage(max_seq = 256)\n-    dp.ParseAllPage(max_seq = 512)\n-    print(len(dp.data))\n-    dp.ParseOnePageWithRule(max_seq = 256)\n-    dp.ParseOnePageWithRule(max_seq = 512)\n-    print(len(dp.data))\n+    # dp.ParseAllPage(max_seq = 256)\n+    # dp.ParseAllPage(max_seq = 512)\n+    # print(len(dp.data))\n+    # dp.ParseOnePageWithRule(max_seq = 256)\n+    # dp.ParseOnePageWithRule(max_seq = 512)\n+    # print(len(dp.data))\n     data = dp.data\n \n     faissretriever = FaissRetriever(model_name, data)\n     faiss_ans = faissretriever.GetTopK(\"如何预防新冠肺炎\", 6)\n"
                },
                {
                    "date": 1732260487102,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,17 +36,17 @@\n         return self.vector_store\n \n if __name__ == \"__main__\":\n     base = \".\"\n-    model_name = \"bge\"\n+    model_name = \"m3e\"\n     model_dict = {\n         \"m3e\": base + \"/pre_train_model/m3e-large\",\n         \"bge\": base + \"/pre_train_model/bge-large-zh-embed\"\n     }\n     model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n-    dp.ParseBlock(max_seq = 512)\n+    # dp.ParseBlock(max_seq = 512)\n     print(len(dp.data))\n     # dp.ParseAllPage(max_seq = 256)\n     # dp.ParseAllPage(max_seq = 512)\n     # print(len(dp.data))\n"
                },
                {
                    "date": 1732260504973,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,9 +54,9 @@\n     # dp.ParseOnePageWithRule(max_seq = 512)\n     # print(len(dp.data))\n     data = dp.data\n \n-    faissretriever = FaissRetriever(model_name, data)\n+    faissretriever = FaissRetriever(model_path, data)\n     faiss_ans = faissretriever.GetTopK(\"如何预防新冠肺炎\", 6)\n     print(faiss_ans)\n     faiss_ans = faissretriever.GetTopK(\"交通事故如何处理\", 6)\n     print(faiss_ans)\n"
                },
                {
                    "date": 1732260614804,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,24 +36,24 @@\n         return self.vector_store\n \n if __name__ == \"__main__\":\n     base = \".\"\n-    model_name = \"m3e\"\n+    model_name = \"bge\"\n     model_dict = {\n         \"m3e\": base + \"/pre_train_model/m3e-large\",\n         \"bge\": base + \"/pre_train_model/bge-large-zh-embed\"\n     }\n     model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n-    # dp.ParseBlock(max_seq = 512)\n+    dp.ParseBlock(max_seq = 512)\n     print(len(dp.data))\n-    # dp.ParseAllPage(max_seq = 256)\n-    # dp.ParseAllPage(max_seq = 512)\n-    # print(len(dp.data))\n-    # dp.ParseOnePageWithRule(max_seq = 256)\n-    # dp.ParseOnePageWithRule(max_seq = 512)\n-    # print(len(dp.data))\n+    dp.ParseAllPage(max_seq = 256)\n+    dp.ParseAllPage(max_seq = 512)\n+    print(len(dp.data))\n+    dp.ParseOnePageWithRule(max_seq = 256)\n+    dp.ParseOnePageWithRule(max_seq = 512)\n+    print(len(dp.data))\n     data = dp.data\n \n     faissretriever = FaissRetriever(model_path, data)\n     faiss_ans = faissretriever.GetTopK(\"如何预防新冠肺炎\", 6)\n"
                },
                {
                    "date": 1732261171071,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,12 +36,13 @@\n         return self.vector_store\n \n if __name__ == \"__main__\":\n     base = \".\"\n-    model_name = \"bge\"\n+    model_name = \"m3e\"\n     model_dict = {\n         \"m3e\": base + \"/pre_train_model/m3e-large\",\n-        \"bge\": base + \"/pre_train_model/bge-large-zh-embed\"\n+        \"bge\": base + \"/pre_train_model/bge-large-zh-embed\",\n+        \"gte\": base + \"/pre_train_model/gte-large-zh-embed\"\n     }\n     model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n"
                },
                {
                    "date": 1732261673894,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,8 +7,14 @@\n from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n from pdf_parse import DataProcess\n import torch\n \n+base = \".\"\n+model_dict = {\n+        \"m3e\": base + \"/pre_train_model/m3e-large\",\n+        \"bge\": base + \"/pre_train_model/bge-large-zh-embed\",\n+        \"gte\": base + \"/pre_train_model/gte-large-zh-embed\"\n+    }\n \n class FaissRetriever(object):\n     # 初始化文档块索引，然后插入faiss库\n     def __init__(self, model_path, data):\n@@ -35,15 +41,11 @@\n     def GetvectorStore(self):\n         return self.vector_store\n \n if __name__ == \"__main__\":\n-    base = \".\"\n+    \n     model_name = \"m3e\"\n-    model_dict = {\n-        \"m3e\": base + \"/pre_train_model/m3e-large\",\n-        \"bge\": base + \"/pre_train_model/bge-large-zh-embed\",\n-        \"gte\": base + \"/pre_train_model/gte-large-zh-embed\"\n-    }\n+    \n     model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n     dp.ParseBlock(max_seq = 512)\n"
                },
                {
                    "date": 1732261702636,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,10 @@\n     }\n \n class FaissRetriever(object):\n     # 初始化文档块索引，然后插入faiss库\n-    def __init__(self, model_path, data):\n+    def __init__(self, model_name, data):\n+        model_name = model_path = model_dict[model_name]\n         self.embeddings  = HuggingFaceEmbeddings(\n                                model_name = model_path,\n                                model_kwargs = {\"device\":\"cuda\"}\n                                # model_kwargs = {\"device\":\"cuda:1\"}\n@@ -44,9 +45,8 @@\n if __name__ == \"__main__\":\n     \n     model_name = \"m3e\"\n     \n-    model_path = model_dict[model_name]\n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n     dp.ParseBlock(max_seq = 512)\n     print(len(dp.data))\n@@ -57,9 +57,9 @@\n     dp.ParseOnePageWithRule(max_seq = 512)\n     print(len(dp.data))\n     data = dp.data\n \n-    faissretriever = FaissRetriever(model_path, data)\n+    faissretriever = FaissRetriever(model_name, data)\n     faiss_ans = faissretriever.GetTopK(\"如何预防新冠肺炎\", 6)\n     print(faiss_ans)\n     faiss_ans = faissretriever.GetTopK(\"交通事故如何处理\", 6)\n     print(faiss_ans)\n"
                },
                {
                    "date": 1732261740646,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,9 @@\n \n class FaissRetriever(object):\n     # 初始化文档块索引，然后插入faiss库\n     def __init__(self, model_name, data):\n-        model_name = model_path = model_dict[model_name]\n+        model_path = model_dict[model_name]\n         self.embeddings  = HuggingFaceEmbeddings(\n                                model_name = model_path,\n                                model_kwargs = {\"device\":\"cuda\"}\n                                # model_kwargs = {\"device\":\"cuda:1\"}\n@@ -43,9 +43,9 @@\n         return self.vector_store\n \n if __name__ == \"__main__\":\n     \n-    model_name = \"m3e\"\n+    model_name = \"gte\"\n     \n     dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n     dp.ParseBlock(max_seq = 1024)\n     dp.ParseBlock(max_seq = 512)\n"
                },
                {
                    "date": 1732268461063,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,9 +11,10 @@\n base = \".\"\n model_dict = {\n         \"m3e\": base + \"/pre_train_model/m3e-large\",\n         \"bge\": base + \"/pre_train_model/bge-large-zh-embed\",\n-        \"gte\": base + \"/pre_train_model/gte-large-zh-embed\"\n+        \"gte\": base + \"/pre_train_model/gte-large-zh-embed\",\n+        \"bce\": base + \"/pre_train_model/bce-base-embed\"\n     }\n \n class FaissRetriever(object):\n     # 初始化文档块索引，然后插入faiss库\n"
                },
                {
                    "date": 1732672106723,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,8 +18,9 @@\n \n class FaissRetriever(object):\n     # 初始化文档块索引，然后插入faiss库\n     def __init__(self, model_name, data):\n+        assert model_name in model_dict.keys(), \"Unknown dense retriever name: {model_name}\"\n         model_path = model_dict[model_name]\n         self.embeddings  = HuggingFaceEmbeddings(\n                                model_name = model_path,\n                                model_kwargs = {\"device\":\"cuda\"}\n"
                },
                {
                    "date": 1732696333616,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n \n class FaissRetriever(object):\n     # 初始化文档块索引，然后插入faiss库\n     def __init__(self, model_name, data):\n-        assert model_name in model_dict.keys(), \"Unknown dense retriever name: {model_name}\"\n+        assert model_name in model_dict.keys(), f\"Unknown dense retriever name: {model_name}.\"\n         model_path = model_dict[model_name]\n         self.embeddings  = HuggingFaceEmbeddings(\n                                model_name = model_path,\n                                model_kwargs = {\"device\":\"cuda\"}\n"
                }
            ],
            "date": 1732257699981,
            "name": "Commit-0",
            "content": "#!/usr/bin/env python\n# coding: utf-8\n\n\nfrom langchain.schema import Document\nfrom langchain.vectorstores import Chroma,FAISS\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom pdf_parse import DataProcess\nimport torch\n\n\nclass FaissRetriever(object):\n    # 初始化文档块索引，然后插入faiss库\n    def __init__(self, model_path, data):\n        self.embeddings  = HuggingFaceEmbeddings(\n                               model_name = model_path,\n                               model_kwargs = {\"device\":\"cuda\"}\n                               # model_kwargs = {\"device\":\"cuda:1\"}\n                           )\n        docs = []\n        for idx, line in enumerate(data):\n            line = line.strip(\"\\n\").strip()\n            words = line.split(\"\\t\")\n            docs.append(Document(page_content=words[0], metadata={\"id\": idx}))\n        self.vector_store = FAISS.from_documents(docs, self.embeddings)\n        del self.embeddings\n        torch.cuda.empty_cache()\n\n    # 获取top-K分数最高的文档块\n    def GetTopK(self, query, k):\n       context = self.vector_store.similarity_search_with_score(query, k=k)\n       return context\n\n    # 返回faiss向量检索对象\n    def GetvectorStore(self):\n        return self.vector_store\n\nif __name__ == \"__main__\":\n    base = \".\"\n    model_name = \"bge\"\n    model_dict = {\n        \"m3e\": base + \"/pre_train_model/m3e-large\",\n        \"bge\": \"bge-large-zh\"\n    }\n    model_path = model_dict[model_name]\n    dp =  DataProcess(pdf_path = base + \"/data/train_a.pdf\")\n    dp.ParseBlock(max_seq = 1024)\n    dp.ParseBlock(max_seq = 512)\n    print(len(dp.data))\n    dp.ParseAllPage(max_seq = 256)\n    dp.ParseAllPage(max_seq = 512)\n    print(len(dp.data))\n    dp.ParseOnePageWithRule(max_seq = 256)\n    dp.ParseOnePageWithRule(max_seq = 512)\n    print(len(dp.data))\n    data = dp.data\n\n    faissretriever = FaissRetriever(model_name, data)\n    faiss_ans = faissretriever.GetTopK(\"如何预防新冠肺炎\", 6)\n    print(faiss_ans)\n    faiss_ans = faissretriever.GetTopK(\"交通事故如何处理\", 6)\n    print(faiss_ans)\n    faiss_ans = faissretriever.GetTopK(\"吉利集团的董事长是谁\", 6)\n    print(faiss_ans)\n    faiss_ans = faissretriever.GetTopK(\"吉利汽车语音组手叫什么\", 6)\n    print(faiss_ans)\n"
        }
    ]
}